{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NizarArdansyah/Capstone-Project-Machine-Learning/blob/main/Model_Tanah.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fTaS80Hn4edu"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ],
      "id": "fTaS80Hn4edu"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ddb1314",
        "outputId": "cf633a0c-96f7-4f39-bde1-c4e318cacbc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "drive.mount('/content/drive/')"
      ],
      "id": "4ddb1314"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8-FzGzk5UKm",
        "outputId": "40129ad8-d402-4e1a-9882-709955f134e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Soil_Types  Training  Validation\n"
          ]
        }
      ],
      "source": [
        "base_dir = '/content/drive/My Drive/Capstone/'\n",
        "!ls \"/content/drive/My Drive/Capstone/\""
      ],
      "id": "K8-FzGzk5UKm"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L0rF8KED566_"
      },
      "outputs": [],
      "source": [
        "soil_dir = os.path.join(base_dir, 'Soil_Types')\n",
        "training_dir = os.path.join(base_dir, 'Training')\n",
        "validation_dir = os.path.join(base_dir, 'Validation')"
      ],
      "id": "L0rF8KED566_"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7hvG4U66aZF",
        "outputId": "f0ae24e1-1213-4c80-fa5a-714f5a6d7437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah Data Train Tiap Kelas\n",
            "Jumlah gambar tanah kuning : 29\n",
            "Jumlah gambar tanah gambut : 30\n",
            "Jumlah gambar tanah laterit : 30\n",
            "Jumlah gambar tanah andosol : 37\n",
            "Jumlah gambar tanah vulkanik : 30\n"
          ]
        }
      ],
      "source": [
        "yellow_dir = os.path.join(soil_dir, 'Tanah_Kuning/')\n",
        "peat_dir = os.path.join(soil_dir, 'Tanah_Gambut/')\n",
        "laterite_dir = os.path.join(soil_dir, 'Tanah_Laterit/')\n",
        "cinder_dir = os.path.join(soil_dir, 'Tanah_Andosol/')\n",
        "black_dir = os.path.join(soil_dir, 'Tanah_Vulkanik/')\n",
        "\n",
        "print(\"Jumlah Data Train Tiap Kelas\")\n",
        "print(\"Jumlah gambar tanah kuning :\", len(os.listdir(yellow_dir)))\n",
        "print(\"Jumlah gambar tanah gambut :\", len(os.listdir(peat_dir)))\n",
        "print(\"Jumlah gambar tanah laterit :\", len(os.listdir(laterite_dir)))\n",
        "print(\"Jumlah gambar tanah andosol :\", len(os.listdir(cinder_dir)))\n",
        "print(\"Jumlah gambar tanah vulkanik :\", len(os.listdir(black_dir)))"
      ],
      "id": "c7hvG4U66aZF"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "NXaA-0yN76cM"
      },
      "outputs": [],
      "source": [
        "#direktori training\n",
        "train_yellow = os.path.join(training_dir, 'Tanah_Kuning/')\n",
        "train_peat = os.path.join(training_dir, 'Tanah_Gambut/')\n",
        "train_laterite = os.path.join(training_dir, 'Tanah_Laterit/')\n",
        "train_cinder = os.path.join(training_dir, 'Tanah_Andosol/')\n",
        "train_black = os.path.join(training_dir, 'Tanah_Vulkanik/')\n",
        "\n",
        "#direktori validation\n",
        "validation_yellow = os.path.join(validation_dir, 'Tanah_Kuning/')\n",
        "validation_peat = os.path.join(validation_dir, 'Tanah_Gambut/')\n",
        "validation_laterite = os.path.join(validation_dir, 'Tanah_Laterit/')\n",
        "validation_cinder = os.path.join(validation_dir, 'Tanah_Andosol/')\n",
        "validation_black = os.path.join(validation_dir, 'Tanah_Vulkanik/')"
      ],
      "id": "NXaA-0yN76cM"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "cellView": "code",
        "id": "7c5d7d0e"
      },
      "outputs": [],
      "source": [
        "def split_data(soil_dir, training_dir, validation_dir, SPLIT_SIZE):\n",
        "  files = []\n",
        "  for filename in os.listdir(soil_dir):\n",
        "    file = soil_dir + filename\n",
        "    if os.path.getsize(file) > 0:\n",
        "      files.append(filename)\n",
        "    else:\n",
        "      print(filename + ' is zero length, so ignoring.')\n",
        "\n",
        "    training_length = int(len(files) * SPLIT_SIZE)\n",
        "    testing_length = int(len(files) - training_length)\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[-testing_length:]\n",
        "  \n",
        "  for filename in training_set:\n",
        "    src_file = soil_dir + filename\n",
        "    dest_file = training_dir + filename\n",
        "    copyfile(src_file, dest_file)\n",
        "    \n",
        "  for filename in testing_set:\n",
        "    src_file = soil_dir + filename\n",
        "    dest_file = validation_dir + filename\n",
        "    copyfile(src_file, dest_file)\n",
        "  pass\n"
      ],
      "id": "7c5d7d0e"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz8RGQtE9PBH",
        "outputId": "c0645d67-1c5a-41a1-c800-321619ebff2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Original yellow soil's directory has 29 images\n",
            "\n",
            "\n",
            "Original peat soil's directory has 30 images\n",
            "\n",
            "\n",
            "Original laterite soil's directory has 30 images\n",
            "\n",
            "\n",
            "Original cinder soil's directory has 37 images\n",
            "\n",
            "\n",
            "Original black soil's directory has 30 images\n",
            "There are 26 images of yellow soil for training\n",
            "There are 27 images of peat soil for training\n",
            "There are 27 images of laterite soil for training\n",
            "There are 33 images of cinder soil for training\n",
            "There are 27 images of black soil for training\n",
            "There are 3 images of yellow soil for validation\n",
            "There are 3 images of peat soil for validation\n",
            "There are 3 images of laterite soil for validation\n",
            "There are 4 images of cinder soil for validation\n",
            "There are 3 images of black soil for validation\n"
          ]
        }
      ],
      "source": [
        "if len(os.listdir(train_yellow)) > 0:\n",
        "  for file in os.scandir(train_yellow):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(train_peat)) > 0:\n",
        "  for file in os.scandir(train_peat):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(train_laterite)) > 0:\n",
        "  for file in os.scandir(train_laterite):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(train_cinder)) > 0:\n",
        "  for file in os.scandir(train_cinder):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(train_black)) > 0:\n",
        "  for file in os.scandir(train_black):\n",
        "    os.remove(file.path)\n",
        "\n",
        "if len(os.listdir(validation_yellow)) > 0:\n",
        "  for file in os.scandir(validation_yellow):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(validation_peat)) > 0:\n",
        "  for file in os.scandir(validation_peat):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(validation_laterite)) > 0:\n",
        "  for file in os.scandir(validation_laterite):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(validation_cinder)) > 0:\n",
        "  for file in os.scandir(validation_cinder):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(validation_black)) > 0:\n",
        "  for file in os.scandir(validation_black):\n",
        "    os.remove(file.path)\n",
        "\n",
        "# Define proportion of images used for training\n",
        "split_size = .9\n",
        "\n",
        "# Run the function\n",
        "# NOTE: Messages about zero length images should be printed out\n",
        "split_data(yellow_dir, train_yellow, validation_yellow, split_size)\n",
        "split_data(peat_dir, train_peat, validation_peat, split_size)\n",
        "split_data(laterite_dir, train_laterite, validation_laterite, split_size)\n",
        "split_data(cinder_dir, train_cinder, validation_cinder, split_size)\n",
        "split_data(black_dir, train_black, validation_black, split_size)\n",
        "\n",
        "\n",
        "# Your function should perform copies rather than moving images so original directories should contain unchanged images\n",
        "print(f\"\\n\\nOriginal yellow soil's directory has {len(os.listdir(yellow_dir))} images\")\n",
        "print(f\"\\n\\nOriginal peat soil's directory has {len(os.listdir(peat_dir))} images\")\n",
        "print(f\"\\n\\nOriginal laterite soil's directory has {len(os.listdir(laterite_dir))} images\")\n",
        "print(f\"\\n\\nOriginal cinder soil's directory has {len(os.listdir(cinder_dir))} images\")\n",
        "print(f\"\\n\\nOriginal black soil's directory has {len(os.listdir(black_dir))} images\")\n",
        "\n",
        "# Training and validation splits. Check that the number of images matches the expected output.\n",
        "print(f\"There are {len(os.listdir(train_yellow))} images of yellow soil for training\")\n",
        "print(f\"There are {len(os.listdir(train_peat))} images of peat soil for training\")\n",
        "print(f\"There are {len(os.listdir(train_laterite))} images of laterite soil for training\")\n",
        "print(f\"There are {len(os.listdir(train_cinder))} images of cinder soil for training\")\n",
        "print(f\"There are {len(os.listdir(train_black))} images of black soil for training\")\n",
        "\n",
        "print(f\"There are {len(os.listdir(validation_yellow))} images of yellow soil for validation\")\n",
        "print(f\"There are {len(os.listdir(validation_peat))} images of peat soil for validation\")\n",
        "print(f\"There are {len(os.listdir(validation_laterite))} images of laterite soil for validation\")\n",
        "print(f\"There are {len(os.listdir(validation_cinder))} images of cinder soil for validation\")\n",
        "print(f\"There are {len(os.listdir(validation_black))} images of black soil for validation\")"
      ],
      "id": "Hz8RGQtE9PBH"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "cellView": "code",
        "id": "35525d12"
      },
      "outputs": [],
      "source": [
        "def train_val_generators(training_dir, validation_dir):\n",
        "\n",
        "  train_datagen = ImageDataGenerator(rescale=1.0/255.,\n",
        "                                     rotation_range=40,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     shear_range=0.2,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     fill_mode='nearest')\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(directory=training_dir,\n",
        "                                                      batch_size=20,\n",
        "                                                      class_mode='categorical',\n",
        "                                                      target_size=(150, 150))\n",
        "\n",
        "  validation_datagen = ImageDataGenerator(rescale=1.0/255.,\n",
        "                                          rotation_range=40,\n",
        "                                          width_shift_range=0.2,\n",
        "                                          height_shift_range=0.2,\n",
        "                                          shear_range=0.2,\n",
        "                                          zoom_range=0.2,\n",
        "                                          horizontal_flip=True,\n",
        "                                          fill_mode='nearest')\n",
        "\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=validation_dir,\n",
        "                                                                batch_size=10,\n",
        "                                                                class_mode='categorical',\n",
        "                                                                target_size=(150, 150))\n",
        " \n",
        "  return train_generator, validation_generator"
      ],
      "id": "35525d12"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2198ef1",
        "outputId": "427a693a-b7aa-4926-9eb6-b5c86fa512d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 140 images belonging to 5 classes.\n",
            "Found 16 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator, validation_generator = train_val_generators(training_dir, validation_dir)"
      ],
      "id": "d2198ef1"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "XcQcpGNvCK4i"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n"
      ],
      "id": "XcQcpGNvCK4i"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "cellView": "code",
        "id": "d88b8b62"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([ \n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(200, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(500, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "  ])\n"
      ],
      "id": "d88b8b62"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DydP521HwoS",
        "outputId": "fc58b3b5-c99f-48d5-cd97-5b0be4512073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 148, 148, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 74, 74, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 72, 72, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 36, 36, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 34, 34, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 17, 17, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 18496)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 200)               3699400   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 500)               100500    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 500)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 2505      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,825,989\n",
            "Trainable params: 3,825,989\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ],
      "id": "0DydP521HwoS"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "oXvioPpsJRL_"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy']) "
      ],
      "id": "oXvioPpsJRL_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36ad5144"
      },
      "source": [
        "Now it is time to train your model!\n"
      ],
      "id": "36ad5144"
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94f6a40a",
        "outputId": "f7556193-67e0-4148-998d-6d9b72ea9a77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "7/7 [==============================] - 1s 204ms/step - loss: 0.3108 - accuracy: 0.8643 - val_loss: 0.7183 - val_accuracy: 0.8750\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - 1s 182ms/step - loss: 0.2782 - accuracy: 0.8929 - val_loss: 0.4409 - val_accuracy: 0.8125\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - 1s 184ms/step - loss: 0.2415 - accuracy: 0.9071 - val_loss: 0.5077 - val_accuracy: 0.8750\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - 1s 180ms/step - loss: 0.2223 - accuracy: 0.9143 - val_loss: 0.4056 - val_accuracy: 0.8750\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 0.3082 - accuracy: 0.8929 - val_loss: 0.5051 - val_accuracy: 0.8125\n",
            "Epoch 6/15\n",
            "7/7 [==============================] - 1s 174ms/step - loss: 0.3050 - accuracy: 0.9000 - val_loss: 0.8435 - val_accuracy: 0.8125\n",
            "Epoch 7/15\n",
            "7/7 [==============================] - 1s 180ms/step - loss: 0.2752 - accuracy: 0.8929 - val_loss: 0.6463 - val_accuracy: 0.8125\n",
            "Epoch 8/15\n",
            "7/7 [==============================] - 1s 184ms/step - loss: 0.3195 - accuracy: 0.8643 - val_loss: 0.5929 - val_accuracy: 0.8750\n",
            "Epoch 9/15\n",
            "7/7 [==============================] - 1s 187ms/step - loss: 0.4610 - accuracy: 0.8286 - val_loss: 0.6942 - val_accuracy: 0.8125\n",
            "Epoch 10/15\n",
            "7/7 [==============================] - 1s 181ms/step - loss: 0.3157 - accuracy: 0.8786 - val_loss: 0.3535 - val_accuracy: 0.8750\n",
            "Epoch 11/15\n",
            "7/7 [==============================] - 1s 189ms/step - loss: 0.3478 - accuracy: 0.8571 - val_loss: 0.4766 - val_accuracy: 0.8750\n",
            "Epoch 12/15\n",
            "7/7 [==============================] - 3s 452ms/step - loss: 0.3466 - accuracy: 0.8786 - val_loss: 0.3783 - val_accuracy: 0.8750\n",
            "Epoch 13/15\n",
            "7/7 [==============================] - 2s 260ms/step - loss: 0.2512 - accuracy: 0.9143 - val_loss: 0.4208 - val_accuracy: 0.8125\n",
            "Epoch 14/15\n",
            "7/7 [==============================] - 1s 185ms/step - loss: 0.3042 - accuracy: 0.8857 - val_loss: 0.3400 - val_accuracy: 0.8750\n",
            "Epoch 15/15\n",
            "7/7 [==============================] - 1s 184ms/step - loss: 0.2531 - accuracy: 0.9143 - val_loss: 0.4523 - val_accuracy: 0.8750\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "# Note that this may take some time.\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator\n",
        "                    )"
      ],
      "id": "94f6a40a"
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "mflZmCmuyALb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98613e32-a507-400c-f702-466b6fca2f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "id": "mflZmCmuyALb"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}